{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12ce9b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "def parse_dot_file_manual(file_path):\n",
    "    \"\"\"\n",
    "    Manually parse a DOT file and create a NetworkX graph.\n",
    "    This method doesn't rely on external DOT parsers.\n",
    "    Handles multi-line attribute definitions properly.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the DOT file\n",
    "        \n",
    "    Returns:\n",
    "        networkx.Graph or networkx.DiGraph: The loaded graph\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # Remove comments\n",
    "        content = re.sub(r'//.*?\\n', '\\n', content)\n",
    "        content = re.sub(r'/\\*.*?\\*/', '', content, flags=re.DOTALL)\n",
    "        \n",
    "        # Determine if it's directed or undirected\n",
    "        is_directed = 'digraph' in content.lower() or '->' in content\n",
    "        \n",
    "        # Create appropriate graph type\n",
    "        if is_directed:\n",
    "            graph = nx.DiGraph()\n",
    "        else:\n",
    "            graph = nx.Graph()\n",
    "        \n",
    "        # Tokenize the content to handle multi-line structures\n",
    "        tokens = _tokenize_dot_content(content)\n",
    "        \n",
    "        i = 0\n",
    "        while i < len(tokens):\n",
    "            token = tokens[i]\n",
    "            \n",
    "            # Skip graph declaration and braces\n",
    "            if token.lower() in ['graph', 'digraph', '{', '}'] or not token.strip():\n",
    "                i += 1\n",
    "                continue\n",
    "            \n",
    "            # Check if this is an edge (look ahead for edge operators)\n",
    "            if i + 2 < len(tokens) and tokens[i + 1] in ['--', '->']:\n",
    "                source = token\n",
    "                edge_op = tokens[i + 1]\n",
    "                target = tokens[i + 2]\n",
    "                i += 3\n",
    "                \n",
    "                # Parse edge attributes\n",
    "                edge_attrs = {}\n",
    "                if i < len(tokens) and tokens[i] == '[':\n",
    "                    attr_tokens, i = _parse_attributes(tokens, i)\n",
    "                    edge_attrs = _parse_attribute_pairs(attr_tokens)\n",
    "                \n",
    "                # Convert numeric values\n",
    "                for key, value in edge_attrs.items():\n",
    "                    if _is_numeric(value):\n",
    "                        edge_attrs[key] = float(value)\n",
    "                \n",
    "                graph.add_edge(source, target, **edge_attrs)\n",
    "                \n",
    "            # Otherwise, it's a node\n",
    "            else:\n",
    "                node = token\n",
    "                i += 1\n",
    "                \n",
    "                # Parse node attributes\n",
    "                node_attrs = {}\n",
    "                if i < len(tokens) and tokens[i] == '[':\n",
    "                    attr_tokens, i = _parse_attributes(tokens, i)\n",
    "                    node_attrs = _parse_attribute_pairs(attr_tokens)\n",
    "                \n",
    "                # Convert numeric values for node attributes\n",
    "                for key, value in node_attrs.items():\n",
    "                    if _is_numeric(value):\n",
    "                        node_attrs[key] = float(value)\n",
    "                \n",
    "                graph.add_node(node, **node_attrs)\n",
    "        \n",
    "        print(f\"Successfully parsed DOT file: {file_path}\")\n",
    "        print(f\"Graph type: {type(graph).__name__}\")\n",
    "        print(f\"Number of nodes: {graph.number_of_nodes()}\")\n",
    "        print(f\"Number of edges: {graph.number_of_edges()}\")\n",
    "        \n",
    "        return graph\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing DOT file: {e}\")\n",
    "        return None\n",
    "\n",
    "def _tokenize_dot_content(content):\n",
    "    \"\"\"Tokenize DOT content handling quoted strings and special characters.\"\"\"\n",
    "    tokens = []\n",
    "    i = 0\n",
    "    \n",
    "    while i < len(content):\n",
    "        char = content[i]\n",
    "        \n",
    "        # Skip whitespace\n",
    "        if char.isspace():\n",
    "            i += 1\n",
    "            continue\n",
    "        \n",
    "        # Handle quoted strings\n",
    "        if char == '\"':\n",
    "            quote_end = i + 1\n",
    "            while quote_end < len(content) and content[quote_end] != '\"':\n",
    "                if content[quote_end] == '\\\\':  # Handle escaped characters\n",
    "                    quote_end += 1\n",
    "                quote_end += 1\n",
    "            if quote_end < len(content):\n",
    "                tokens.append(content[i+1:quote_end])  # Remove quotes\n",
    "                i = quote_end + 1\n",
    "            else:\n",
    "                i += 1\n",
    "        \n",
    "        # Handle special characters\n",
    "        elif char in '[]{}=;':\n",
    "            tokens.append(char)\n",
    "            i += 1\n",
    "        \n",
    "        # Handle edge operators\n",
    "        elif char == '-':\n",
    "            if i + 1 < len(content) and content[i + 1] == '-':\n",
    "                tokens.append('--')\n",
    "                i += 2\n",
    "            elif i + 1 < len(content) and content[i + 1] == '>':\n",
    "                tokens.append('->')\n",
    "                i += 2\n",
    "            else:\n",
    "                i += 1\n",
    "        \n",
    "        # Handle regular tokens (identifiers, numbers)\n",
    "        else:\n",
    "            token_start = i\n",
    "            while i < len(content) and not content[i].isspace() and content[i] not in '[]{}=;-\"':\n",
    "                i += 1\n",
    "            if i > token_start:\n",
    "                tokens.append(content[token_start:i])\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "def _parse_attributes(tokens, start_index):\n",
    "    \"\"\"Parse attribute list starting from '[' and return tokens and end index.\"\"\"\n",
    "    if tokens[start_index] != '[':\n",
    "        return [], start_index\n",
    "    \n",
    "    attr_tokens = []\n",
    "    i = start_index + 1\n",
    "    bracket_count = 1\n",
    "    \n",
    "    while i < len(tokens) and bracket_count > 0:\n",
    "        token = tokens[i]\n",
    "        if token == '[':\n",
    "            bracket_count += 1\n",
    "        elif token == ']':\n",
    "            bracket_count -= 1\n",
    "        \n",
    "        if bracket_count > 0:\n",
    "            attr_tokens.append(token)\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    return attr_tokens, i\n",
    "\n",
    "def _parse_attribute_pairs(attr_tokens):\n",
    "    \"\"\"Parse attribute tokens into key-value pairs.\"\"\"\n",
    "    attrs = {}\n",
    "    i = 0\n",
    "    \n",
    "    while i < len(attr_tokens):\n",
    "        if i + 2 < len(attr_tokens) and attr_tokens[i + 1] == '=':\n",
    "            key = attr_tokens[i]\n",
    "            value = attr_tokens[i + 2]\n",
    "            attrs[key] = value\n",
    "            i += 3\n",
    "        else:\n",
    "            i += 1\n",
    "    \n",
    "    return attrs\n",
    "\n",
    "def _is_numeric(value):\n",
    "    \"\"\"Check if a string represents a numeric value.\"\"\"\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "def write_networkx_to_dot_manual(graph, filename):\n",
    "    \"\"\"\n",
    "    Manual implementation to write NetworkX graph to DOT format.\n",
    "    This works without requiring pygraphviz.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    graph : networkx.Graph\n",
    "        The NetworkX graph to write\n",
    "    filename : str\n",
    "        Output filename\n",
    "    \"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        # Determine if graph is directed\n",
    "        if graph.is_directed():\n",
    "            f.write(\"digraph G {\\n\")\n",
    "            edge_sep = \" -> \"\n",
    "        else:\n",
    "            f.write(\"graph G {\\n\")\n",
    "            edge_sep = \" -- \"\n",
    "        \n",
    "        # Write nodes with attributes\n",
    "        for node in graph.nodes():\n",
    "            attrs = graph.nodes[node]\n",
    "            if attrs:\n",
    "                attr_str = \", \".join([f'{k}=\"{v}\"' for k, v in attrs.items()])\n",
    "                f.write(f'  \"{node}\" [{attr_str}];\\n')\n",
    "            else:\n",
    "                f.write(f'  \"{node}\";\\n')\n",
    "        \n",
    "        # Write edges with attributes\n",
    "        for u, v in graph.edges():\n",
    "            attrs = graph.edges[u, v]\n",
    "            if attrs:\n",
    "                attr_str = \", \".join([f'{k}=\"{v}\"' for k, v in attrs.items()])\n",
    "                f.write(f'  \"{u}\"{edge_sep}\"{v}\" [{attr_str}];\\n')\n",
    "            else:\n",
    "                f.write(f'  \"{u}\"{edge_sep}\"{v}\";\\n')\n",
    "        \n",
    "        f.write(\"}\\n\")\n",
    "    \n",
    "    print(f\"Graph successfully written to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9a9d88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully parsed DOT file: ../graph/clustered_graph.dot\n",
      "Graph type: Graph\n",
      "Number of nodes: 40\n",
      "Number of edges: 666\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pydot\n",
    "\n",
    "        # Read the DOT file using NetworkX\n",
    "G = parse_dot_file_manual('../graph/clustered_graph.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db28e4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = sum(nx.get_edge_attributes(G, name='weight').values())\n",
    "u=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd3f6fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import netbone as nb\n",
    "from netbone.filters import boolean_filter, threshold_filter, fraction_filter\n",
    "# Apply filters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "819880a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High Salience Skeleton Filter\n",
      "Graph successfully written to ../graph/clustered_graph_hss_backbone.dot\n"
     ]
    }
   ],
   "source": [
    "# Remove all edges from hss_backbone.graph where 'in_backbone' == False\n",
    "hss_backbone = nb.high_salience_skeleton(G)\n",
    "backbone = boolean_filter(hss_backbone)\n",
    "write_networkx_to_dot_manual(backbone, '../graph/clustered_graph_hss_backbone.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1dacdfe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doubly Stochastic Filter\n",
      "Graph successfully written to ../graph/clustered_graph_ds_backbone.dot\n"
     ]
    }
   ],
   "source": [
    "ds_backbone = nb.doubly_stochastic(G)\n",
    "backbone = boolean_filter(ds_backbone)\n",
    "write_networkx_to_dot_manual(backbone, '../graph/clustered_graph_ds_backbone.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19fe086b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H-Backbone Filter\n",
      "Graph successfully written to ../graph/clustered_graph_h_backbone.dot\n"
     ]
    }
   ],
   "source": [
    "h_backbone = nb.h_backbone(G)\n",
    "backbone = boolean_filter(h_backbone)\n",
    "write_networkx_to_dot_manual(backbone, '../graph/clustered_graph_h_backbone.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6907184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Spanning Tree\n",
      "Graph successfully written to ../graph/clustered_graph_mst_backbone.dot\n"
     ]
    }
   ],
   "source": [
    "mst_backbone = nb.maximum_spanning_tree(G)\n",
    "backbone = boolean_filter(mst_backbone)\n",
    "write_networkx_to_dot_manual(backbone, '../graph/clustered_graph_mst_backbone.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7641c02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric Distance Filter\n",
      "Graph successfully written to ../graph/clustered_graph_md_backbone.dot\n"
     ]
    }
   ],
   "source": [
    "md_backbone = nb.metric_distance_backbone(G)\n",
    "backbone = boolean_filter(md_backbone)\n",
    "write_networkx_to_dot_manual(backbone, '../graph/clustered_graph_md_backbone.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e884c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultrametric Distance Filter\n",
      "Graph successfully written to ../graph/clustered_graph_umd_backbone.dot\n"
     ]
    }
   ],
   "source": [
    "umd_backbone = nb.ultrametric_distance_backbone(G)\n",
    "backbone = boolean_filter(umd_backbone)\n",
    "write_networkx_to_dot_manual(backbone, '../graph/clustered_graph_umd_backbone.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cff3cc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Citation here\n",
      "Graph successfully written to ../graph/clustered_graph_pmfg_backbone.dot\n"
     ]
    }
   ],
   "source": [
    "pmfg_backbone = nb.pmfg(G)\n",
    "backbone = boolean_filter(pmfg_backbone)\n",
    "write_networkx_to_dot_manual(backbone, '../graph/clustered_graph_pmfg_backbone.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dfb9e88e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m plam_backbone = \u001b[43mnb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m backbone = boolean_filter(plam_backbone)\n\u001b[32m      3\u001b[39m write_networkx_to_dot_manual(backbone, \u001b[33m'\u001b[39m\u001b[33m../graph/clustered_graph_pla_backbone.dot\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/netbone/structural/plam.py:29\u001b[39m, in \u001b[36mplam\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m     27\u001b[39m nx.set_edge_attributes(g, \u001b[38;5;28;01mFalse\u001b[39;00m, name=\u001b[33m'\u001b[39m\u001b[33min_backbone\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m g.nodes():\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     source, target, weight = \u001b[43mget_max_weight_edge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m     g[source][target][\u001b[33m'\u001b[39m\u001b[33min_backbone\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Backbone(g, method_name=\u001b[33m\"\u001b[39m\u001b[33mPrimary Linkage Analysis\u001b[39m\u001b[33m\"\u001b[39m, property_name=\u001b[33m\"\u001b[39m\u001b[33mweight\u001b[39m\u001b[33m\"\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m, compatible_filters=[boolean_filter], filter_on=\u001b[33m'\u001b[39m\u001b[33mEdges\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/netbone/structural/plam.py:16\u001b[39m, in \u001b[36mget_max_weight_edge\u001b[39m\u001b[34m(graph, node)\u001b[39m\n\u001b[32m     14\u001b[39m         max_weight = weight\n\u001b[32m     15\u001b[39m         max_edge = (node, neighbor)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmax_edge\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m, max_edge[\u001b[32m1\u001b[39m], max_weight\n",
      "\u001b[31mTypeError\u001b[39m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "plam_backbone = nb.plam(G)\n",
    "backbone = boolean_filter(plam_backbone)\n",
    "write_networkx_to_dot_manual(backbone, '../graph/clustered_graph_pla_backbone.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8379b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph successfully written to ../graph/clustered_graph_nc_backbone.dot\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nc_backbone = nb.noise_corrected(G,False)\n",
    "edges_to_remove = [(u, v) for u, v, d in nc_backbone.graph.edges(data=True) if float(d.get('score')) <0.1]\n",
    "nc_backbone.graph.remove_edges_from(edges_to_remove)\n",
    "write_networkx_to_dot_manual(nc_backbone.graph, '../graph/clustered_graph_nc_backbone.dot')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
